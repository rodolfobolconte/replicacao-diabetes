---
title: "2 - Execução de Modelos de Aprendizagem"
author: Rodolfo Bolconte
date: 26/06/21
output:
    #word_document: default
    html_document:
        rmdformats::readthedown
---

<style>
body {
text-align: justify}
</style>

```{r echo=FALSE}
knitr::opts_chunk$set(tidy = TRUE,
                      warning=FALSE, message=FALSE,
                      fig.width = 8,
                      fig.height = 6,
                      fig.align="center"
                      )
```

Repositório dos Dados Originais: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&CycleBeginYear=2015
Documentação dos Dados: https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DIQ_I.htm

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(boot)
library(broom)
library(grid)
library(gridExtra)
library(quantreg)
library(scales)
```

## Carregamento dos Dados

```{r}
#CARREGAMENTO DO CONJUNTO DE DADO
dados = read_csv(here::here("code/diabetes_random.csv"))

dados = dados %>% mutate(diabetico=if_else(diabetico==2, 0, 1))

dataset = dados[2:10]

dataset$diabetico = factor(dataset$diabetico, levels=c(0,1))
```

```{r}
#REAMOSTRAGEM DOS DADOS UTILIZANDO HOLDOUT 56:14:30
library(caTools)
set.seed(123)

#56% DOS DADOS PARA TREINO = 78 AMOSTRAS
split_train = sample.split(dataset$diabetico, SplitRatio=78)
ds_train = subset(dataset, split_train == T)

#RESTANTE DOS DADOS
ds_restante = subset(dataset, split_train == F)

#14% DOS DADOS PARA VALIDAÇÃO = 20 AMOSTRAS
split_validation = sample.split(ds_restante$diabetico, SplitRatio=20)
ds_validation = subset(ds_restante, split_validation == T)

#30% DOS DADOS RESTANTES DO CONJUNTO ORIGINAL PARA TESTE = 42 AMOSTRAS
ds_test = subset(ds_restante, split_validation == F)
```

```{r}
#FUNÇÃO DE ACURÁCIA
acc <- function(original, previsao) {
  matriz_confusao = table(original, previsao)
  vn = matriz_confusao[1]
  fn = matriz_confusao[2]
  fp = matriz_confusao[3]
  vp = matriz_confusao[4]

  acc = (vn+vp)/(vn+fn+fp+vp)
  
  acc
}
```


```{r}
#EXECUÇÃO DO RANDOM FOREST
library(randomForest)

#CRIAÇÃO E TREINO DO MODELO
rf_model = randomForest(x=ds_train[-9],
                                    y=ds_train$diabetico,
                                    ntree=50, random_state=0)

#PREVISÃO DOS DADOS DE VALIDAÇÃO
rf_prev_validation = predict(rf_model, ds_validation)
acc(ds_validation$diabetico, rf_prev_validation)

#PREVISAO DOS DADOS DE TESTE
rf_prev_test = predict(rf_model, ds_test)
acc(ds_test$diabetico, rf_prev_test)
rf_data_ic = data.frame(original=ds_test$diabetico, previsao=rf_prev_test)
```

```{r}
#EXECUÇÃO DO SVM
library(e1071)

#CRIAÇÃO E TREINO DO MODELO
svm_model = randomForest(x=ds_train[-9],
                        y=ds_train$diabetico)

#PREVISÃO DOS DADOS DE VALIDAÇÃO
svm_prev_validation = predict(svm_model, ds_validation)
acc(ds_validation$diabetico, svm_prev_validation)

#PREVISAO DOS DADOS DE TESTE
svm_prev_test = predict(svm_model, ds_test)
acc(ds_test$diabetico, svm_prev_test)
svm_data_ic = data.frame(original=ds_test$diabetico, previsao=svm_prev_test)
```

```{r}
#CALCULO DE THETA
acuracia <- function(dataset, indices) {
  random = dataset %>%
    slice(indices)
  
  acc(random$original, random$previsao)
}

#FUNÇÃO QUE EXECUTA BOOTSTRAP E CALCULA THETA
ic_acuracia = function(dataset) {
    
  #GERAÇÃO DO BOOTSTRAP
  resultado_bootstrap = boot(data = dataset,
         statistic = acuracia,
         R = 2000) %>%
  tidy(conf.level = .95,
       conf.method = "bca",
       conf.int = TRUE)

  resultado_bootstrap
}
```


```{r}
rf_ic = ic_acuracia(rf_data_ic)
svm_ic = ic_acuracia(svm_data_ic)

models_data_ic = bind_rows(rf_ic %>% mutate(modelo="Random Forest"), svm_ic %>% mutate(modelo="Support Vector Machine"))
```

```{r}
models_data_ic %>% 
  ggplot(aes(y=modelo)) +
  geom_point(aes(x=statistic), size=4) +
  geom_errorbar(aes(xmin=conf.low, xmax=conf.high), width=.13) +
  labs(x="\nIntervalo de Confiança de Acurácia", y="Modelos\n") +
  theme(text=element_text(size=16)) +
  scale_y_discrete(labels = c("Random\nForest", "Support\nVector\nMachine")) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(limits = c(0,1))

ggsave("f-ic-previsao-modelos.pdf")
```


```{r}
#CALCULO DE THETA
diferenca_acuracia <- function(rf_dataset, indices, svm_dataset) {
  rf_random = rf_dataset %>%
    slice(indices)
  
  svm_random = svm_dataset %>%
    slice(indices)
  
  acc(rf_random$original, rf_random$previsao) - acc(svm_random$original, svm_random$previsao)
}

#FUNÇÃO QUE EXECUTA BOOTSTRAP E CALCULA THETA
ic_diferenca_acuracia = function(rf_dataset, svm_dataset) {
    
  #GERAÇÃO DO BOOTSTRAP
  resultado_bootstrap = boot(data = rf_dataset,
         statistic = diferenca_acuracia,
         R = 2000,
         svm_dataset=svm_dataset) %>%
  tidy(conf.level = .95,
       conf.method = "bca",
       conf.int = TRUE)

  resultado_bootstrap
}
```

```{r}
diferenca_models_ic = ic_diferenca_acuracia(rf_data_ic, svm_data_ic)
```

```{r}
diferenca_plot = diferenca_models_ic %>% 
  ggplot(aes(y="")) +
  geom_point(aes(x=statistic), size=4) +
  geom_errorbar(aes(xmin=conf.low, xmax=conf.high), width=.07) +
  labs(x=NULL, y=NULL) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(limits=c(-1,1))

g = grid.arrange(diferenca_plot,
             left = textGrob("Support Vector Machine",
                               gp = gpar(fontsize=16), r=90),
             right = textGrob("Random Forest",
                               gp = gpar(fontsize=16), r=270),
             bottom = textGrob("Intervalo de Confiança da Diferença de Acurácia",
                               gp = gpar(fontsize=16)))

g

#ggsave("f-ic-diferenca-modelos.pdf", g)
```